import { LLMResult } from './llm.js';

/**
 * Mock LLM service for testing without making actual API calls
 * Returns predefined responses based on process type
 */

const MOCK_RESPONSES: Record<string, string> = {
  research: `# Research Summary

## Key Concepts

This is a comprehensive research summary generated by the mock LLM service.

- **Concept 1**: First important concept explained in detail
- **Concept 2**: Second key concept with relevant context
- **Concept 3**: Third essential concept for understanding

## Important Context

The mock service provides realistic responses that mimic actual AI output. This allows for:

1. Testing without API costs
2. Consistent, reproducible test results
3. Fast development iteration

## Recent Developments

Recent advancements in this area include improved testing methodologies and better integration patterns.

## Related Topics

- Testing strategies
- Mock service patterns
- E2E testing best practices

## Reliable Sources

1. Testing Documentation - comprehensive guide
2. Best Practices Guide - industry standards
3. Example Repository - working examples
`,

  summarize: `## Summary

This is a concise summary of the main points:

- The content discusses important concepts and ideas
- Key takeaways include testing strategies and best practices
- The information is relevant for development and implementation

The mock service ensures consistent test results without external dependencies.
`,

  expand: `# Expanded Analysis

## Deeper Explanation

This idea represents an important approach to solving common development challenges. By using mock services, we can:

- Eliminate external dependencies during testing
- Ensure consistent, reproducible results
- Reduce testing costs and time

## Examples & Use Cases

**Use Case 1: Development Testing**
When building new features, developers can test AI integration without waiting for API responses or incurring costs.

**Use Case 2: CI/CD Pipelines**
Automated tests run quickly and reliably without external API dependencies.

**Use Case 3: Demo Environments**
Demos work consistently without requiring API keys or internet connectivity.

## Different Perspectives

From a testing perspective, mock services provide isolation and control. From a development perspective, they enable rapid iteration and experimentation.

## Implications

Using mock services can significantly improve development velocity and test reliability while reducing operational costs.

## Questions to Consider

1. How can we ensure mock responses stay realistic?
2. What's the right balance between mock and real testing?
3. How do we validate that mocks match real behavior?
4. When should we use integration tests with real APIs?
5. How do we maintain mock data as APIs evolve?
`,

  actionplan: `# Action Plan

## Goal Clarification

The goal is to implement comprehensive testing for the AI notes application without requiring external API calls.

## Action Steps

1. **Set up Mock LLM Service** (30 minutes)
   - Create mock response generator
   - Implement process type routing
   - Add configuration flags

2. **Configure Environment Variables** (15 minutes)
   - Add USE_MOCK_LLM flag
   - Update documentation
   - Set up test environment

3. **Install Playwright** (20 minutes)
   - Add Playwright dependencies
   - Configure test settings
   - Set up test fixtures

4. **Write E2E Tests** (2-3 hours)
   - Note creation tests
   - AI processing tests
   - Tree navigation tests
   - Deletion tests

5. **Set up Test Docker Environment** (45 minutes)
   - Create test docker-compose
   - Configure test database
   - Add test scripts

6. **Run and Validate Tests** (30 minutes)
   - Execute full test suite
   - Fix any failures
   - Document results

7. **Update Documentation** (20 minutes)
   - Add testing guide
   - Document mock usage
   - Include troubleshooting

8. **Code Review and Refinement** (1 hour)
   - Review test coverage
   - Improve test quality
   - Add edge case tests

## Prerequisites

- Docker and Docker Compose installed
- Node.js 20+ for local development
- Basic understanding of E2E testing

## Success Criteria

- ✅ All tests pass without external API calls
- ✅ Tests complete in under 2 minutes
- ✅ Mock responses are realistic
- ✅ Tests cover all major user journeys
- ✅ Documentation is clear and complete

## Potential Obstacles

1. **Docker networking issues** - Solution: Use docker-compose networking
2. **Timing issues in tests** - Solution: Use proper Playwright waiters
3. **Database state management** - Solution: Reset database between tests
`,
};

/**
 * Mock implementation of callClaude that returns predetermined responses
 */
export async function callClaudeMock(prompt: string): Promise<LLMResult> {
  // Simulate API delay (faster than real API for testing)
  await new Promise((resolve) => setTimeout(resolve, 500));

  // Determine process type from prompt
  let processType = 'research'; // default
  if (prompt.toLowerCase().includes('summarize')) {
    processType = 'summarize';
  } else if (prompt.toLowerCase().includes('expand')) {
    processType = 'expand';
  } else if (prompt.toLowerCase().includes('action plan')) {
    processType = 'actionplan';
  }

  const content = MOCK_RESPONSES[processType] || MOCK_RESPONSES.research;

  // Simulate realistic token counts
  const inputTokens = Math.floor(prompt.length / 4);
  const outputTokens = Math.floor(content.length / 4);

  console.log(`✓ Mock LLM call (${processType}) - ${inputTokens + outputTokens} tokens`);

  return {
    content,
    tokensUsed: {
      input: inputTokens,
      output: outputTokens,
      total: inputTokens + outputTokens,
    },
    model: 'claude-sonnet-4-mock',
  };
}

/**
 * Check if mock mode is enabled
 */
export function isMockEnabled(): boolean {
  return process.env.USE_MOCK_LLM === 'true';
}
